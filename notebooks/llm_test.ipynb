{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "\n",
    "# 1. 加载 openai 密钥\n",
    "sys.path.append('../..')\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# 2. 加载指定路径下所有文件\n",
    "workpath = \"../data/output\"\n",
    "excel_file = f\"{workpath}/wos_coredata_cleaned.xlsx\"\n",
    "csv_file = f\"{workpath}/paper_title_abstract.csv\"\n",
    "\n",
    "\n",
    "def xlsx2csv():\n",
    "    # 用pandas.read_excel()读取xlsx文件，并返回一个DataFrame对象\n",
    "    df = pd.read_excel(excel_file).loc[:, [\"Title\", 'Abstract']]\n",
    "    # 用pandas.DataFrame.to_csv()将DataFrame对象写入到csv文件中\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "def load_files():\n",
    "    # 设置源信息为论文名称\n",
    "    loader = CSVLoader(csv_file, source_column=\"Title\")\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "\n",
    "# 3. 分割文本\n",
    "\n",
    "\n",
    "def split_doc():\n",
    "    chunk_size = 200  # 设置块大小\n",
    "    chunk_overlap = 40  # 设置块重叠大小\n",
    "    # 初始化文本分割器\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        # 设置 换行, 句号, 逗号, 空格 为分隔符 (按顺序切割)\n",
    "        separators=[\"\\n\", \"(?<=\\. )\", \",\", \" \"]\n",
    "    )\n",
    "    # 调用分割器分割文本\n",
    "    data = load_files()\n",
    "    split_texts = text_splitter.split_documents(data)\n",
    "    print(\"分割前:\", len(data), \"\\n分割后:\", len(split_texts))\n",
    "    return split_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 加载 embedding 模型\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 5. 连接向量数据库并创建表\n",
    "\n",
    "# PGVector 数据库连接字符串\n",
    "CONNECTION_STRING = \"postgresql+psycopg2://postgres:123qwe@localhost:4321/essay_anaylsis\"\n",
    "# PGVector 模块将尝试创建一个表, 注意表的名称并不是集合的名称\n",
    "# 因此, 请确保集合名称是唯一的, 并且用户具有创建表的权限.\n",
    "COLLECTION_NAME = \"llm_langchain_essay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore():\n",
    "    split_texts = split_doc()\n",
    "    vectordb = PGVector.from_documents(\n",
    "        documents=split_texts,\n",
    "        embedding=embedding,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        connection_string=CONNECTION_STRING,\n",
    "    )\n",
    "# create_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 连接已有的向量数据库, 作为检索器\n",
    "def conn_vectorstore():\n",
    "    store = PGVector(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        connection_string=CONNECTION_STRING,\n",
    "        embedding_function=embedding,\n",
    "    )\n",
    "    # 使用矢量数据库作为检索器\n",
    "    retriever = store.as_retriever()\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 提出问题, 进行相似性检索\n",
    "# question = \"Please list the specific application of SIF in the field of agriculture.\"\n",
    "# question = \"Please list the application of SIF in agricultural yield estimation,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 构建 Prompt 模板\n",
    "qa_template = \"\"\"结合以下上下文片段来回答最后的问题。\n",
    "如果你不知道答案，只需说不知道，不要试图编造答案。\n",
    "在回答的最后一定要说\"感谢您的提问！\"\n",
    "{context}\n",
    "问题：{question}\n",
    "有用的回答：\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=qa_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't know how many papers there are in the context. Thank you for your question!\n"
     ]
    }
   ],
   "source": [
    "# 11. 生成 QA 问答链\n",
    "# 加载模型和检索器\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "retriever = conn_vectorstore()\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "essay_auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
